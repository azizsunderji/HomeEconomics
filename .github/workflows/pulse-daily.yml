name: Pulse Daily Briefing

on:
  schedule:
    - cron: "30 9 * * *"   # 5:30am ET during EDT (UTC-4)
    - cron: "30 10 * * *"  # 5:30am ET during EST (UTC-5)
  workflow_dispatch:

jobs:
  daily:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    env:
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
      APIFY_API_KEY: ${{ secrets.APIFY_API_KEY }}
      GMAIL_TOKEN: ${{ secrets.GMAIL_TOKEN }}
      GMAIL_TOKENS: ${{ secrets.GMAIL_TOKENS }}
      FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
      NOTION_API_KEY: ${{ secrets.NOTION_API_KEY }}
      PUSHOVER_TOKEN: ${{ secrets.PUSHOVER_TOKEN }}
      PUSHOVER_USER: ${{ secrets.PUSHOVER_USER }}
      BLUESKY_HANDLE: ${{ secrets.BLUESKY_HANDLE }}
      BLUESKY_APP_PASSWORD: ${{ secrets.BLUESKY_APP_PASSWORD }}
      DATA_LAKE_PATH: /tmp/data-lake
      DATA_LAKE_CATALOG_PATH: /tmp/reference/data_lake_catalog.md

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r pulse/requirements.txt

      - name: Install rclone
        run: sudo apt-get update && sudo apt-get install -y rclone

      - name: Configure rclone
        run: |
          mkdir -p ~/.config/rclone
          cat > ~/.config/rclone/rclone.conf << 'EOF'
          [dropbox]
          type = dropbox
          token = ${{ secrets.RCLONE_DROPBOX_TOKEN }}
          EOF

      - name: Pull Pulse DB from Dropbox
        run: |
          mkdir -p pulse/data
          rclone copy "dropbox:Home Economics/Data/Pulse/pulse.db" pulse/data/ \
            --verbose --stats-one-line || echo "No existing DB — starting fresh"

      - name: Pull data lake for claim verification
        run: |
          mkdir -p /tmp/data-lake /tmp/reference
          # Pull key directories (selective — most important parquet files)
          rclone copy "dropbox:Home Economics/Data/Price/" /tmp/data-lake/Price/ \
            --include "*.parquet" --verbose --stats-one-line --transfers 4
          rclone copy "dropbox:Home Economics/Data/Redfin/" /tmp/data-lake/Redfin/ \
            --include "monthly_metro.parquet" --verbose --stats-one-line
          rclone copy "dropbox:Home Economics/Data/State_Migration/" /tmp/data-lake/State_Migration/ \
            --include "*.parquet" --verbose --stats-one-line
          rclone copy "dropbox:Home Economics/Data/PopulationEstimates/" /tmp/data-lake/PopulationEstimates/ \
            --include "*.parquet" --verbose --stats-one-line
          rclone copy "dropbox:Home Economics/Data/ACS_1Y/" /tmp/data-lake/ACS_1Y/ \
            --include "*.parquet" --verbose --stats-one-line --transfers 4
          rclone copy "dropbox:Home Economics/Data/GSS/" /tmp/data-lake/GSS/ \
            --include "*.parquet" --verbose --stats-one-line
          rclone copy "dropbox:Home Economics/Data/Crosswalks/" /tmp/data-lake/Crosswalks/ \
            --include "*.parquet" --verbose --stats-one-line
          rclone copy "dropbox:Home Economics/Reference/data_lake_catalog.md" /tmp/reference/ \
            --verbose --stats-one-line || true
          echo "=== Data lake size ===" && du -sh /tmp/data-lake/

      - name: Run daily pipeline
        working-directory: pulse/scripts
        run: python run_pipeline.py daily

      - name: Sync DB back to Dropbox
        if: always()
        run: |
          rclone copy pulse/data/ "dropbox:Home Economics/Data/Pulse/" \
            --include "pulse.db" --include "*.json" \
            --verbose --stats-one-line
