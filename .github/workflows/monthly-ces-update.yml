name: Monthly CES Data Update

on:
  # Runs on the 5th of each month at 2:00 AM Eastern (handles EDT/EST)
  schedule:
    - cron: "0 6 5 * *"  # 2:00am ET during EDT (UTC-4)
    - cron: "0 7 5 * *"  # 2:00am ET during EST (UTC-5)
  workflow_dispatch: {}   # Allow manual trigger for testing

jobs:
  update-ces-data:
    runs-on: ubuntu-latest
    env:
      TZ: America/New_York
      BLS_API_KEY: a7d81877b6374d11a6b7e15fa63b5f9b
      REMOTE_BASE: ${{ secrets.REMOTE_BASE }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ces-viewer/requirements.txt
      
      - name: Update CES data from BLS API
        run: |
          echo "Updating CES historical data with recent months..."

          # Check if historical data exists, if not create it
          if [ -f "ces-viewer/data/ces_historical_data.json" ]; then
            echo "Historical data exists, updating with recent data only..."
            python ces-viewer/scripts/update_ces_recent.py
          else
            echo "No historical data found, fetching full history (this will take ~15-20 minutes)..."
            python ces-viewer/scripts/fetch_ces_historical_data.py --start-year 1939 --output ces-viewer/data/ces_historical_data.json
          fi

          # Generate recession periods
          echo "Generating recession periods..."
          cd ces-viewer/scripts && python process_recessions.py && cd ../..

          # Keep a copy of the regular data file for backwards compatibility
          echo "Creating regular data file for backwards compatibility..."
          python ces-viewer/scripts/fetch_ces_data.py --output ces-viewer/data/ces_data.json --start-year 2015 || echo "Note: Regular data fetch failed, continuing with historical data"
      
      - name: Verify data integrity
        run: |
          echo "Historical data file:"
          if [ -f "ces-viewer/data/ces_historical_data.json" ]; then
            ls -lh ces-viewer/data/ces_historical_data.json
            python -c "import json; data=json.load(open('ces-viewer/data/ces_historical_data.json')); print(f'{data[\"meta\"][\"series_count\"]} series, {data[\"meta\"][\"total_data_points\"]:,} points, {data[\"meta\"][\"earliest_year\"]}-{data[\"meta\"][\"latest_year\"]}')"
          fi
          echo ""
          echo "Regular data file:"
          if [ -f "ces-viewer/data/ces_data.json" ]; then
            ls -lh ces-viewer/data/ces_data.json
            python -c "import json; data=json.load(open('ces-viewer/data/ces_data.json')); print(f'{len(data[\"series\"])} series loaded')"
          fi
          echo ""
          echo "Recession periods:"
          if [ -f "ces-viewer/data/recession_periods.json" ]; then
            ls -lh ces-viewer/data/recession_periods.json
            python -c "import json; data=json.load(open('ces-viewer/data/recession_periods.json')); print(f'{len(data[\"recessions\"])} recession periods')"
          fi
      
      - name: Install lftp
        run: sudo apt-get update && sudo apt-get install -y lftp
      
      - name: Upload to server via SFTP
        env:
          HOST: ${{ secrets.SFTP_HOST }}
          USER: ${{ secrets.SFTP_USER }}
          KEY: ${{ secrets.SFTP_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H $HOST >> ~/.ssh/known_hosts 2>/dev/null || true
          
          # Upload to WordPress uploads directory
          echo "Starting upload..."
          
          # Create temp directory for upload
          mkdir -p upload_temp

          # Copy all data files
          cp ces-viewer/data/ces_data.json upload_temp/ 2>/dev/null || echo "No regular data file"
          cp ces-viewer/data/ces_historical_data.json upload_temp/ 2>/dev/null || echo "No historical data file"
          cp ces-viewer/data/recession_periods.json upload_temp/ 2>/dev/null || echo "No recession periods file"

          # Copy HTML viewer
          cp ces-viewer/src/ces-viewer.html upload_temp/index.html
          
          # Use mirror -R like all working workflows
          lftp -e "
            set sftp:auto-confirm yes;
            set sftp:connect-program 'ssh -i ~/.ssh/id_rsa';
            set net:max-retries 3;
            set net:timeout 60;
            set net:reconnect-interval-base 5;
            open -u $USER,dummy sftp://$HOST;
            cd ${REMOTE_BASE}/live/ces;
            put upload_temp/ces_data.json;
            put upload_temp/ces_historical_data.json;
            put upload_temp/recession_periods.json;
            put upload_temp/index.html;
            bye
          " || echo "Upload finished with warnings"
          
          echo "Upload completed with exit code: $?"
      
      - name: Generate update report
        run: |
          echo "## CES Data Update Report" > summary.md
          echo "" >> summary.md
          echo "**Updated:** $(date +'%Y-%m-%d %H:%M %Z')" >> summary.md
          echo "" >> summary.md
          echo "### Statistics" >> summary.md
          python -c "
          import json
          data = json.load(open('ces-viewer/data/ces_data.json'))
          print(f'- Total series: {len(data[\"series\"])}')
          print(f'- Date range: {data[\"meta\"][\"start_date\"]} to {data[\"meta\"][\"end_date\"]}')
          print(f'- File size: {len(json.dumps(data)) / 1024 / 1024:.1f} MB')
          " >> summary.md
          cat summary.md
      
      - name: Upload summary artifact
        uses: actions/upload-artifact@v4
        with:
          name: update-summary
          path: summary.md
          retention-days: 30